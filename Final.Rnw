\documentclass[a4paper, 10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[spanish, es-tabla]{babel}
\usepackage{amsmath,amsfonts,amssymb,amsthm,float,bbm}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{url}
\author{Jorge Carlos Urteaga \and Víctor R. Martinez}
\title{Aprendizaje de Máquina \\ Projecto Final}
\date{\today}
\decimalpoint
    
\begin{document}
\SweaveOpts{concordance=TRUE}

\maketitle

\section{Introducción}
Se estima que cada año mueren cerca de 250,000 personas a causa de una picadura de alacrán \cite{Chippaux}. De las 1500 especies de alacranes, las más peligrosas se encuentran en zonas altamente endémicas como, por ejemplo: México, Sudamérica, África, Medio Oriente, y la India. Tan sólo en México se pueden encontrar 200 especies de alacranes de las cuales el \emph{Centuroides noxius} (Durango y Nayarit) y el \emph{Centuroides limpidus limpidus} (Jalisco, Guerrero y Michoacán) son letales para un ser humano. El número de casos de picadura de alacrán registrados en el país alcanza los 280,000 al año, con un número de muertes promedio cercano a 70 en los últimos años \cite{epidemiologia}. El identificar un alacrán como peligroso, utilizando información extraída de sus características morfológicas, podría disminuir el número de muertes en el mundo. \\

\subsection{Morfología de un alacrán}

\begin{figure}[tb]
  \begin{center}
    \includegraphics[width=9cm]{s4.png}
  \end{center}
  \caption{Partes del cuerpo de un alacrán}
  \label{fig:cuerpo}
\end{figure}

Por sus características morfológicas, podemos dividir el cuerpo de un alacrán en 3 partes: la parte frontal (\emph{cephalothorax}); el abdomen (\emph{ophistosoma}), y la cola (\emph{metosoma}). El \emph{cephalothorax}, también llamado \emph{prosoma}, comprende los ojos, quelicerido, pedipalpos, quelas y cuatro pares de patas. El \emph{ophistosoma} o mesosoma consiste en los 7 segmentos que comprenden el dorso y el vientre. La \emph{metosoma} comprende los últimos 6 segmentos, los primeros cinco corresponden a las quillas dorsales y en el ultimo segmento se encuentra el telson y el aguijón. La figura \ref{fig:cuerpo} muestra a detalle cada una de las partes.

\subsection{Objetivo}
En este trabajo investigamos diferentes métodos para clasificar un alacrán como peligroso o no peligroso utilizando fotografías de los arácnidos. Planteamos un algoritmo para procesar la imagen y obtener 140 variables que nos permitan distinguir si el arácnido es venenoso o no.

\section{Datos}

\begin{figure}[tb]
  \centering
  \begin{subfigure}[b]{0.3\textwidth}
    \includegraphics[width=3cm]{s1.png}
  \end{subfigure}%
  \begin{subfigure}[b]{0.3\textwidth}
    \includegraphics[width=3cm]{s2.png}
  \end{subfigure}%
  \begin{subfigure}[b]{0.3\textwidth}
    \includegraphics[width=3cm]{s3.png}
  \end{subfigure}%
  \caption{Ejemplos de las fotografías utilizadas}
  \label{fig:Alacranes}
\end{figure}

Los datos fueron obtenidas por 218 fotografías tomadas a alacranes vivos de las especies \emph{C. Limpydus}, \emph{C. Noxius} y \emph{Dejovies}  en un ambiente controlado que consistió en la cámara de un dispositivo móvil, un refractario y etiquetas adherentes para sostener al alacrán. La cámara utilizada tenía 8 MP ($3264 \times 2448$) píxeles con una apertura (f/2,4) y auto-enfoque. Se usa un recipiente redondo para mantener al alacrán al centro, y el adhesivo permite que el alacrán conserve posición fija con un fondo liso (ver figura \ref{fig:Alacranes}). Para obtener las variables a analizar, cada fotografía pasó por un pre-procesamiento para retirar todo el ruido y detectar al alacrán. Después, se realizó un análisis sobre la forma del arácnido, y se almacenó las propiedades principales. Este proceso resultó en una muestra de 218 observaciones sobre un espacio de 140 variables.

\subsection{Procesamiento de la imagen}
Se analizaron las capas de RGB a través del histograma de color para determinar la capa y los intervalos donde se encuentra el alacrán. Terminando este proceso, se erosiona y se dilata la imagen para retirar el ruido del fondo. Para detectar cada una de las zonas del cuerpo, se revisa el cambio en el área a partir de la ubicación del centro de masa. El análisis morfológico se realiza a partir de los 7 momentos invariantes de Hu \cite{Hu}. Esto da lugar a 140 valores representando las características principales de cada individuo.

\section{Procesamiento de los datos}
Los datos se importan a \textbf{R}, donde son escalados y reducidos para eliminar efectos nocivos de las unidades. Separamos los datos en 5 subgrupos para realizar validaciones cruzadas. Para observar el comportamiento de nuestros modelos, reducimos la dimensionalidad del problema a sus dos primeros componentes principales, los cuales acumulan más del 70\% de la varianza.

<<>>=
library(ggplot2)
library(e1071)
library(plyr)
library(reshape2)
library(nnet)
library(randomForest)
set.seed(107346)

alacranes <- read.csv("csvlist1.csv")
alacranes[which(alacranes$tipo == 1111), c("tipo")] <- 0
alacranes[which(alacranes$tipo == 2222), c("tipo")] <- 1
alacranes$tipo <- as.factor(alacranes$tipo)
#Quitamos la columna ID
alacranes <- alacranes[,!names(alacranes) %in% c("ID")]

#Creacion de las folds
obs <- sample(seq(1, dim(alacranes)[1]),dim(alacranes)[1], replace=F)
max <- length(obs)/5
kfolds <- split(obs, ceiling(seq_along(obs)/max))

#Cuadricula para dibujar las componentes
dat.x <- expand.grid(Comp.1 = seq(-30,30,0.5),
                     Comp.2 = seq(-20,20,0.5))

#Escalamos las variables a mu = 0, sigma = 1
alacranes.scaled <- data.frame(scale(alacranes[,-141]),
                               tipo = alacranes$tipo)

pca <- princomp(~., data=alacranes.scaled[, -141],
                cor = TRUE, na.action=na.exclude)
datos.red <- data.frame(pca$scores[,1:40],
                        tipo = alacranes.scaled$tipo)
@

Como podemos ver en la figura \ref{fig:comp2}, los alacranes no venenosos se encuentran agrupados en el centro de los datos rodeados por alacranes venenosos. Es claro que un modelo lineal sería incapaz de separar de manera adecuada los datos, necesitamos un modelo capaz de generar áreas de clasificación circulares.

<<fig=TRUE>>=
ggplot(aes(x = Comp.1, y = Comp.2, color = tipo),
       data = datos.red) + geom_point() + xlim(-30, 30) + ylim(-20, 20)
@

\section{Métodos}
\subsection{Red neuronal}
Nuestra primera aproximación al problema fue mediante el uso de una red neuronal. Se entrenó una red neuronal con 12 neuronas en la capa escondida (número determinado de manera empírica) con decaimiento ($10^{-9}$) en un máximo de 1000 iteraciones. Para medir el comportamiento de la red, se utilizó un procedimiento de validación cruzada a 5 iteraciones.
<<>>=
ann.cross.validation <- sapply(seq(1,5), function(i){
  train <- datos.red[unlist(kfolds[c(-i)]),]
  test <- datos.red[kfolds[[i]],]
  invisible(capture.output(ann <- nnet(tipo ~ ., data = train, size = 12,
              decay = 1E-9, maxit = 1000)))
  preds <- predict(ann, newdata = test)
  mean(preds == test$tipo)
})
mean(ann.cross.validation)
@
En todas las iteraciones de validación cruzada la red convergió. El resultado final fue decepcionante, ya que la red sólo fue capaz de predecir $72.465\%$ de los casos. Como se verá en la siguiente sección, la máquina de soporte vectorial alcanzó mejores resultados en comparación.

\subsection{Máquina de soporte vectorial}
El segundo método estudiado fueron las máquinas de soporte vectorial. Debido a la forma estudiada de los datos se optó por utilizar un \emph{kernel} de tipo radial, con gamma igual a $2$ (determinado empíricamente). De nueva cuenta recurrimos a la validación cruzada de 5 iteraciones para determinar el mejor parámetro de castigo $C$. El espacio explorado fueron las potencias de 10 desde $-3$ hasta $5$. La siguiente figura muestra el promedio de la certeza del estimado junto con sus barras de error estándar con parámetro $C$ en escala logarítmica. Podemos ver que para $C$ pequeñas, el desempeño del estimador es estadísticamente más bajo que para $C > 1$.

<<fig=TRUE>>=
cross.validation <- sapply(c(0.0001, 0.001,0.005, 0.01,0.05,
                             0.1, 0.5, 1, 2, 3, 5, 10, 50,
                             100, 250, 500, 1000, 5000,
                             10000, 15000, 1000000),function(C){
  medias.C <- sapply(seq(1, 5), function(i){
    #train <- datos.red[unlist(kfolds[c(-i)]),]
    #test <- datos.red[kfolds[[i]],]
    
    train <- alacranes.scaled[unlist(kfolds[c(-i)]),]
    test <- alacranes.scaled[kfolds[[i]],]
    
    svm.c <- svm(tipo ~ ., data = train, kernel = "radial",
                 gamma = 2, cost = C)
    preds <- predict(svm.c, newdata = test)
    mean(preds == test$tipo)
  })
})
cross.validation <- t(cross.validation)
cv.summarize <- data.frame(C = c(0.0001, 0.001,0.005, 0.01,0.05,
                                 0.1, 0.5, 1, 2, 3, 5, 10, 50,
                                 100, 250, 500, 1000, 5000,
                                 10000, 15000, 1000000),
                           mean = rowSums(cross.validation)/5,
                           sd = apply(cross.validation, 1, sd))
max(cv.summarize$mean)
ggplot(aes(x = log(C), y = mean),
       data = cv.summarize) + geom_errorbar(aes(ymin = mean -sd,
                                                ymax = mean + sd,
                                                width=.1)) + geom_point()
@

Para $C > 1$, este clasificador obtuvo una tasa media de clasificación de $86.879\%$ con una desviación estándar de $0.06403$. 

De nueva cuenta, podemos graficar el comportamiento del estimador en dos dimensiones (a partir de los principales factores encontrados). A continuación se muestra como es que el SVM de \emph{kernel} radial con parámetro de castigo $C = 100$ clasifica los puntos del espacio $\mathbb{R}^2$. 

<<fig =TRUE>>=
svm.opt <- svm(tipo ~ Comp.1 + Comp.2, data = datos.red,
               kernel = "radial", gamma = 2, cost = 100)
dat.x$preds.1 <- predict(svm.opt, newdata = dat.x)
ggplot(dat.x, aes(x = Comp.1, y = Comp.2, 
                  colour = preds.1)) + 
  geom_point(size = 1) +
  geom_point(aes(x = Comp.1, y = Comp.2,
                 color = tipo),
             data = datos.red,
             size = 3) + xlim(-30, 30) + ylim(-20, 20)
@
\subsubsection{Sensibilidad, Precisión y score F1}
Nos interesa saber que tan bueno es el desempeño de nuestro modelo al clasificar una muestra de ejemplos. En primer lugar obtenemos separamos nuestros datos reducidos en una muestra de 80\% entrenamiento y 20\% prueba. Para asegurar que la muestra de entrenamiento tenga tanto muestras positivas como muestras negativas, recurrimos a un proceso de muestreo estratificado donde seleccionamos un subconjunto de cada grupo a clasificar de acuerdo a su tamaño relativo en los datos.

<<>>=
idx.tipo1 <- sample(which(alacranes.scaled$tipo == 1), .8 * 174)
idx.tipo0 <- sample(which(alacranes.scaled$tipo == 0), .8 * 0.7372881 * 62)
train <- alacranes.scaled[c(idx.tipo1, idx.tipo0),]
test <- alacranes.scaled[-c(idx.tipo1, idx.tipo0),]

#Shuffle data
train <- train[sample(dim(train)[1]),]
test <- test[sample(dim(test)[1]),]
@

Entrenamos nuestro clasificador SVM utilizando la muestra de entrenamiento y predecimos las categorías de los ejemplos de prueba. Obtenemos la matriz de confusión (una relación visual que nos permite determinar el número de aciertos y errores del clasificador).
<<>>=
svm.opt <- svm(tipo ~ ., data = train, kernel = "radial", gamma = 2, cost = 100)
preds.opt <- predict(svm.opt, newdata = test)
t.confusion <- table(preds.opt, test$tipo, deparse.level = 2)
t.confusion
@

Para medir el desempeño del clasificador, obtenemos las medidas de sensibilidad (tasa de detección de los ejemplos positivos), precisión (valor predictivo positivo) y F1 (medida que combina precisión y sensibilidad).
<<>>=
prec.svm <- t.confusion[1] / (t.confusion[1] + t.confusion[3])
prec.svm
recall.svm <- t.confusion[1] / (t.confusion[1] + t.confusion[2])
recall.svm
f1.svm <- 2 * (prec.svm * recall.svm) / (prec.svm + recall.svm)
f1.svm
@

\subsubsection{Sesgo y Varianza del modelo}
Ahora nos interesa saber si es posible conseguir mejores tasas de clasificación con un clasificador SVM y la manera de hacerlo. Para esto, estudiamos el error de entrenamiento y el error de prueba a distintos tamaños de muestras. Para cada tamaño $n$ era importante asegurarnos que la muestra de entrenamiento tuviera ejemplos de ambas categorías, pues de no ser así, el modelo SVM no sería capaz de obtener los hiper-planos separadores (pues no hay nada que separar). Por esta razón, utilizamos un muestreo estratificado como se muestra a continuación

Al revolver los datos (último paso) nos aseguramos de que, aun en el peor de los casos, una muestra de tamaño 49 tendrá ambas categorías con probabilidad muy alta (cercana a 1). En nuestros experimentos encontramos que el tamaño de la muestra podía ser bastante más bajo. 

Generamos las curvas comparativas de error de entrenamiento y error de prueba para ver si el error que tenemos es producto de sesgo (y no vale la pena agrandar el tamaño de muestra) o varianza (y una muestra más grande podría mejorar nuestro modelo).
<<fig=TRUE>>=
errs <- sapply(seq(20, dim(train)[1]), function(i){
  svm.opt <- svm(tipo ~ ., data = train[1:i,],
                 kernel = "radial", gamma = 2, cost = 100)
  #Err train
  preds.train <- predict(svm.opt, newdata = train[1:i,])
  err.train <- mean(preds.train != train[1:i,]$tipo)
  #Err test
  preds.test <- predict(svm.opt, newdata = test)
  err.test <- mean(preds.test != test$tipo)
  list(i, err.train, err.test)
})
errs <- t(errs)
errs.df.m<- melt(data.frame(i = unlist(errs[,1]),
                            err.train = unlist(errs[,2]),
                            err.test = unlist(errs[,3]))
                 , id=c("i"))
ggplot(aes(x = i, y = value, colour=variable),
       data = errs.df.m) + geom_line()
@

En esta gráfica podemos observar que las curvas de entrenamiento y validación se encuentran separadas y existe una tendencia de la curva de validación a la baja. Esto sugiere que nuestro error es producto de varianza y que necesitamos obtener una muestra de mayor tamaño para reducir el error.

\subsection{Bosques Aleatorios}
Por último estudiamos el procedimiento de bosques aleatorios. En este caso, en cada experimento entrenamos un bosque formado por 350 árboles que discriminan los datos utilizando el criterio de máxima entropía (\emph{maxEnt}).

De nueva cuenta utilizamos validación cruzada en 5 iteraciones para estimar el error promedio y desviación estándar de la tasa de clasificación del bosque.

<<>>=
tree.cross.validation <- sapply(seq(1,5), function(i){
  train <- datos.red[unlist(kfolds[c(-i)]),]
  test <- datos.red[kfolds[[i]],]
  rf <- randomForest(tipo~.,data=train, ntree=350, importance=TRUE)
  preds <- predict(rf, newdata = test)
  mean(preds == test$tipo)
})
m.tree <- mean(tree.cross.validation)
m.tree
sd.tree <- sd(tree.cross.validation)
sd.tree
@

Encontramos que en promedio el bosque aleatorio tendrá una tasa media de clasificación del \Sexpr{m.tree * 100}\% con una variación de \Sexpr{sd.tree} puntos.

La siguiente figura muestra el comportamiento del bosque aleatorio en las dos componentes principales más importantes.

<<fig=TRUE>>=
rf.opt.2 <- randomForest(tipo ~ Comp.1 + Comp.2, 
                         data = datos.red,
                         ntree = 350,
                         importance=TRUE)
dat.x$preds.rf <- predict(rf.opt.2, newdata = dat.x)
ggplot(dat.x, aes(x = Comp.1,
                  y = Comp.2,
                  colour = preds.rf)) + 
  geom_point(size = 1) + geom_point(aes(x = Comp.1,
                                        y = Comp.2,
                                        color = tipo),
                                    data = datos.red,
                                    size = 3) + 
  xlim(-30,30) + ylim(-20,20)
@

\subsubsection{Sensibilidad, Precisión y score F1}
Para hacer posible una comparación sobre los modelos, calculamos las mismas métricas que en la sección anterior sobre el mismo conjunto de datos utilizado por el SVM. La matriz de confusión para el bosque aleatorio está dada por 
<<>>=
rf.opt <- randomForest(tipo ~ ., data = train, importance = TRUE)
preds.opt <- predict(rf.opt, newdata = test)
t.confusion <- table(preds.opt, test$tipo, deparse.level = 2)
t.confusion
@

Mientras que las medidas de precisión, sensibilidad y el score F1 son
<<>>=
prec.rf <- t.confusion[1] / (t.confusion[1] + t.confusion[3])
prec.rf
recall.rf <- t.confusion[1] / (t.confusion[1] + t.confusion[2])
recall.rf
f1.rf <- 2 * (prec.svm * recall.svm) / (prec.svm + recall.svm)
f1.rf
@

\subsubsection{Sesgo y Varianza del modelo}
Por último, investigamos las maneras en que podemos mejorar el modelo de bosque aleatorio midiendo el error de entrenamiento y prueba a distintos tamaños de muestras.

<<>>=
errs <- sapply(seq(20, dim(train)[1]), function(i){
  rf.opt <- randomForest(tipo ~ ., data = train[1:i,])
  #Err train
  preds.train <- predict(rf.opt, newdata = train[1:i,])
  err.train <- mean(preds.train != train[1:i,]$tipo)
  #Err test
  preds.test <- predict(rf.opt, newdata = test)
  err.test <- mean(preds.test != test$tipo)
  list(i, err.train, err.test)
})
errs <- t(errs)
errs.df.m<- melt(data.frame(i = unlist(errs[,1]),
                            err.train = unlist(errs[,2]), 
                            err.test = unlist(errs[,3])), 
                 id=c("i"))
ggplot(aes(x = i, 
           y = value, 
           colour=variable), 
       data = errs.df.m) + geom_line()
@
De nueva cuenta vemos una tendencia del error de validación a la baja, y una diferencia notable entre el error de entrenamiento y el error de prueba. Esto nos da indicación de que el modelo mejoraría si obtuviéramos más pruebas de entrenamiento.


\section{Conclusiones}
De acuerdo a sus características, podemos plantear el problema de distinguir dos tipos de alacranes: no-venenosos y venenosos. A partir de una serie de medidas, se obtuvieron 236 observaciones sobre un espacio de 140 variables. Mediante el procedimiento de análisis de componentes principales, podemos reducir el espacio de variables a sólo 40 acumulando un 97\% de la varianza total, aunque en el transcurso de este trabajo no hubo necesidad pues los algoritmos elegidos corrían sin problema alguno en la totalidad de los datos.
Comparamos dos distintos métodos de clasificación: Máquinas de soporte vectorial y Bosques Aleatorios. Mediante validación cruzada de 5 iteraciones obtuvimos las principales métricas para comparar estos algoritmos. La tabla \ref{tbl:compMod} muestra la comparación.

\begin{table}
  \centering
  \caption{Comparación de las principales métricas de los modelos}
  \begin{tabular}{|c|c|c|c|}
    \hline
    & \textbf{Precisión} & \textbf{Sensibilidad} & \textbf{F1}\\
    \hline
    SVM & \Sexpr{prec.svm} & \Sexpr{recall.svm} & \Sexpr{f1.svm}\\
    \hline
    R.F. & \Sexpr{prec.rf} & \Sexpr{recall.rf} & \Sexpr{f1.rf}\\
    \hline
  \end{tabular}
  \label{tbl:compMod}
\end{table}

Es interesante notar que ambos modelos tienen el mismo score F1, pero varían en precisión y sensibilidad. 

Utilizando un análisis de sesgo y varianza encontramos que ambos modelos se podrían mejorar si obtenemos una muestra mucho más grande, ya que se notó una tendencia del error de prueba hacia la baja y una separación muy amplia entre el error de validación y el de entrenamiento.

\subsection{?`Qué modelo es mejor?}
Para distinguir los modelos consideremos un ejemplo. Tenemos un alacrán del cual no sabemos si es venenoso o no. Supongamos que se lo presentamos a nuestro modelo y este asegura que no es peligroso. Si en realidad el arácnido era venenoso, nuestro modelo habrá puesto en riesgo nuestra salud. En cambio, si el modelo dice que es venenoso pero en realidad no lo era, no pasa de que nos preocupemos un poco y que nos toque una inyección que no correspondía. El primer error se conoce como el error tipo II y al segundo como tipo I.

De esta manera, queremos elegir el modelo que minimice el error tipo II. Para el tamaño de muestra obtenido hasta el momento, el modelo con menor tasa de error del tipo II es el SVM ya que no asigna ningún alacrán venenoso a la categoría de no peligrosos mientras que el bosque aleatorio tiene 3 fallas. Estos resultados resultan muy débiles y faltaría volver a medir con una muestra más grande.

\begin{thebibliography}{9}

\bibitem{Chippaux}
  Chippaux, J.P., Goyffon, M.
  \emph{Epidemiology of scorpionism: a global appraisal}.
  Acta Tropica 107, 2, pp. 71–9, 2010
  
\bibitem{epidemiologia}
  Dirección General de Epidemeología de la Secretaría de Salud.
  \url{http://www.epidemiologia.salud.gob.mx/}
  
\bibitem{Hu}
  Hu, M.K.
  \emph{Visual Pattern Recognition by Moment Invariants}.
  IRE, Transactions on Information Theory,pp. 179 - 187, 1962
  
\end{thebibliography}

\end{document}